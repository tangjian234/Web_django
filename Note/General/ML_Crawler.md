#1.
[ML_Crawler.md](file:///c:/Local/Work/ML_Name/Note/ML_Crawler.md)

- [ML_Crawler.md](file:///c:/Local/Work/ML_Name/Note/ML_Crawler.md)

[![GitHub Issues](https://img.shields.io/github/issues/zalandoresearch/flair.svg)](https://github.com/zalandoresearch/flair/issues)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)
[![Travis](https://img.shields.io/travis/zalandoresearch/flair.svg)](https://travis-ci.org/zalandoresearch/flair)

## Todo

- [ ] Scaffolding of basic plan , IO , time line : [V_2][d_1]
- [ ] Get the web scrappy download and study [V_2][d_1]
  - [ ] Get the basic reference website of scrappy [V_2][d_4]
    - [ ] [link](#scrappy)

## Reference

### scrappy

## Vision

- <Crawler>:
  - Crawler from web get the STEM names
  - Contain : ML technology

## Objective

## Content :

### Reading 1: Scrapy Tutorial

- [Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html)

An open source and collaborative framework for extracting the data you need from websites.

In a fast, simple, yet extensible way.

1. <Question: >

2. <Answer: >

   1. Creating a new Scrapy project
   2. Writing a spider to crawl a site and extract data
   3. Exporting the scraped data using the command line
   4. Changing spider to recursively follow links
   5. Using spider arguments

## Reference

- [Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html)

- [scrapy org](https://scrapy.org/)
