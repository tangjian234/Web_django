# ML_Amazon_product_Crawler.md

- [ML_Amazon_product_Crawler.md](file:///C:/Local/Work/ML_Name/Note/ML_Amazon_product/ML_Amazon_product_Crawler.md) )

[![GitHub Issues](https://img.shields.io/github/issues/zalandoresearch/flair.svg)](https://github.com/zalandoresearch/flair/issues)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)
[![Travis](https://img.shields.io/travis/zalandoresearch/flair.svg)](https://travis-ci.org/zalandoresearch/flair)

## Todo

[09-07]

- - 1.  how to run proxy :
    2.  how to get the scrappy run, get the old work run
    3.  how to get header run
    4.
    5.  build a ps1 file , give a amazon link and get the product info open it using code

## Vision

## Objective

- develop anti -anti crawler

#### Strategy.

[09-07]

1. Simple one : Run beautiful soup.

- - - bs_lib.py

2. More complex, long, comprehensive one runs crappy.

- develop anti -anti crawler

## Content

### how to get header run

- Multiple headers
  // STUB

### How to run proxy

// STUB
https proxy

### Get the scrappy run,

// STUB

get the old work run

## Reference
